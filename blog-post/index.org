#+TITLE:  Lambda calculus
#+EMAIL:  well1912@gmail.com
#+AUTHOR: Justin Lange
#+HTML_HEAD: <script type="text/javascript" src="lambda.js"></script>
#+HTML_HEAD: <style type="text/css">body {color: #333333; max-width: 50em; margin: auto;} a {color: #333333;}</style>
#+OPTIONS: html-postamble:nil

* A simple programming language

Lambda calculus is a very simple programming language. It was
created as a way of modeling algorithms in the 1930s when people were
wondering about how to classify formal languages (like programming
languages). In particular, lambda calculus was provided as an
example of a language with language that one cannot prove will or will
not halt. lambda calculus is interesting because, despite its
simplicity, it can be used to model any computer language!

Lambda calculus is very simple. Like normal programming languages,
we have variables. We also have anonymous functions, denoted with the
lambda, a single parameter, and a lambda calculus expression as the
body. Finally, there are applications of those functions, which
replace uses of the function's parameter with the operand of the
function. Here are some basic lambda calculus expressions, and their
"results":

: x              ; x                               -> x
: f x y          ; f(x)(y)
: λx.x y         ; (lambda x: x)(y)                -> y
: (λx.λy.x) y z  ; (lambda x: (lambda y: x))(y)(z) -> z

Notice in the last example how the function returns another
function. This can be used to represent functions of many parameters,
and is called "currying." Furthermore, notice how ~f x y~ means "apply
~f~ to ~x~, then that result to ~y~." Finally, in lambda calculus
there are no "unbound variable errors." A variable which is "unbound"
is instead said to be "free" in lambda calculus, and is merely
returned as is.

* Church encoding

With just variables, functions, and applications, we have a
way of replicating any algorithm. How can this be true if our language
doesn't have numbers, operators on those numbers, loops, strings, or
the myriad of features contained in languages like Python?

First off, how little can we get away with? We know that strings are
really just data structures holding numbers which are used to encode
characters, so if we have numbers and a basic data structure we can
have strings. Similarly, if we have the numbers 1 and 0, we can
pretend those also mean "true" and "false."

** Numbers

It turns out that we can encode numbers as functions, in the same way
that we're used to having numbers represent strings. First, we
represent zero:

: ZERO = λf.λx.x  ; lambda f: (lambda x: x)

Then we represent positive numbers with a different of n to zero as
the application of f n times to the normal result of zero:

: ONE = λf.λx.f x            ; lambda f: (lambda x: f(x))
: TWO = λf.λx.f (f x)        ; lambda f: (lambda x: f(f(x)))
: THREE = λf.λx.f (f (f x))  ; lambda f: (lambda x: f(f(f(x))))
etc.

Notice how instead of having a value which represents zero, we use a
parameter on a function, and instead of having a function which adds 1
to its input, we have another parameter. We can apply our Python
representions to those values to "translate" our encoding into a
normal Python number:

: lambda_three = lambda f: (lambda x: f(f(f(x))))
: python_add1 = lambda x: x + 1
: python_zero = 0
: lambda_three(python_add1)(python_zero)  # 3

We can abstract the concept of incrementing a number easily enough:

: λn.λf.λx.(f (n f x))

This is a function that says "take a number (i.e., a function which
receives a representation of add1 and zero) and return one greater
than that number (i.e., return another function which takes a
representation of add1 and zero, and apply the original number to that
add1 and zero, but then apply add1 just one more time).

Addition is easy enough to get from here. Because our numbers are just
functions which take add1 and zero and apply add1 a number of times to
zero, we can supply "zero" as one of the numbers and add1 as itself:

: λn.λm.n ADD1 m

or, substituting ADD1 for its definition above:

: λn.λm.n (λn.λf.λx.(f (n f x))) m

Multiplication, exponentiation, subtraction, and division are all
possible to represent in lambda calculus. From here, boolean operators
are simple.

sub1, the opposite of add1, is difficult to define. Here it is:

: SUB1 = λn.λf.λx.n (λg.λh. h (g f)) (λu.x) (λu.u)

Try to simplify ~SUB1 (λf.λx.f (f x))~ by hand to see how it computes
2-1 = 1. Notice how ~SUB1 (λf.λx.x)~ is ~(λf.λx.x)~ (i.e., using this
encoding, 0-1 = 0).

** Booleans

Here we define false and true. They are functions which take two
values, one to be returned as meaning "true" and the other to be
returned as meaning "false."

: TRUE = λt.λf.t   ; lambda t: (lambda f: t)
: FALSE = λt.λf.f  ; lambda t: (lambda f: f)

Which is true and which is false? It doesn't matter as long as we're
consistent with our decision, but notice how the second is identical
to how we represent zero. For this (admittedly weak) reason, we'll
call the first true and the second false. Once again, we can convert
these values to their Python equivalents by simply applying the real
True and False:

: (lambda t: (lambda f: t))(True)(False)  # True
: (lambda t: (lambda f: f))(True)(False)  # False

Pretty basic! If-then-else statements can be constructed by applying
the boolean to the then and else branches:

: IF = λx.λt.λf.x t f  ; lambda x: (lambda t: (lambda f: x(t)(f)))

For example, suppose we want to return ~A~ if some expression is true
or ~B~ otherwise. First, we define a function that takes "some
expression":

: λx ...

And we fill in its body by applying our if-then-else to that
expression, as well as ~A~ and ~B~:

: λx.(λx.λt.λf.x t f) x A B

which has a body we can reduce to:

: λx.x A B

Because we know true takes two values and returns the first, and false
does the same but returns the second, the above form is clearly
correct.

** Linked Lists

Unsurprisingly, we can represent data structures as functions as
well. Here is a function which takes two values and binds them as a
tuple:

: PAIR = λa.λb.λf.f a b

Instead of returing a data structure, we return a function which takes
a function as its argument and applies that function to the values
created in the data structure. How about getting those values back?

: HEAD = λp.p (λa.λb.a)
: TAIL = λp.p (λa.λb.b)

** Encoding with functions
   
The concept of encoding numbers, booleans, and other data types in
lambda calculus using abstractions is called Church encoding. This is
due to Alonzo Church, the inventor of lambda calculus.

* Reduction strategies

Before we talk about recursion, it's important that we talk about two
major ways of making lambda calculus expressions more simple. In
particular, we care about whether a functions argument gets reduced
before it gets substituted as an argument. If we do reduce an argument
fully before applying it, we are using applicative order. Otherwise,
we are using normal order. This is glossing over an important fact of
lambda calculus, and the way that it is /not/ a programming
language: there is no single way to reduce a function
application. However, more useful for us is normal order
reduction. Although this is not how programming languages are normally
evaluated (Python, including others, are applicative order; lazy
languages like Haskell more closely resemble normal order), we choose
it because it means that if a function has a "finished" form, that
form will be returned. Take, for example, the following:

: (λi.x) ((λx.x x)(λx.x x))

If we first evaluate ~((λx.x x)(λx.x x))~, as in applicative order
reduction, we enter an infinite loop:

: (λi.x) ((λx.x x)(λx.x x))
: (λi.x) ((λx.x x)(λx.x x))
etc.

However, if we do not attempt to unravel the operand first, we
immediately return the free variable x.

* Recursion

How about loops? Clearly we don't have any sort of iteration
structure. Can we recur? The answer is yes, but without a way to
define values, how are we supposed to have a function refer to itself?
First we define our recursive function instead as a function which
takes a parameter which means "me" or "recur", and returns how it
would normally be defined. Then we write a function which takes a
function as its argument and hands that function itself, but a version
of itself which can also refer to itself. There are infinitely many
such functions which can do this (and they are called fixed point
combinators), but one of the most simple ones is called the Y
combinator. Here it is:

: Y = λf.(λx.f(x x))(λx.f(x x))

To see it in action, let's define a recursive add. In the below
example, a is merely a parameter which means "add":

: ZERO? = λn.n (λx.TRUE) FALSE

: ADD = Y (λa.λm.λn. IF (ZERO? m) n (a (SUB1 m) (ADD1 n)))

* A lambda calculus reducer in Python

Here is a lambda calculus reducer in Python, with both normal order
and applicative order reducers. Here, an ~abstraction~ indicates a
lambda abstraction. For example, ~λf.f f~ is entered like so:

: abstraction('f', application('f', 'f'))

Here are the reducers:

: from collections import namedtuple
:
: abstraction = namedtuple('abstraction', 'param body')
: application = namedtuple('application', 'lhs rhs')
:
:
: def applicative_reduce(term):
:     if isinstance(term, application):
:         param, body = applicative_reduce(term.rhs)
:         return substitute(param, body, applicative_reduce(term.lhs))
:     else:
:         return term
:
:
: def normal_reduce(term):
:     if isinstance(term, application):
:         param, body = applicative_reduce(term.rhs)
:         return substitute(param, body, term.lhs)
:     else:
:         return term

Note how ~applicative_reduce~ evaluates both the operator and the
operand, while ~normal_reduce~ merely passes in the operand. Neither
do anything when the term is an abstraction.

: def substitute(param, body, x):
:     if param == body:
:         return x
:     elif isinstance(body, str):
:         return body
:     elif isinstance(body, application):
:         lhs, rhs = application
:         return application(
:             substitute(param, lhs, x),
:             substitute(param, rhs, x)
:         )
:     elif param == body.param:
:         return body
:     else:
:         return abstraction(body.param, substitute(param, body.body, x))

~substitute~ will only replace variables with ~x~ as long as those
variables are not bound within another function. Notice the
conditional ~elif param == body.param~: if the parameter we're
replacing is equal to the parameter in the abstraction we've
encountered, we merely return that abstraction. Otherwise, we keep the
abstraction as is except for the body, which we substitute.

: def fix(reducer, term):
:     prev = None
:     while term != prev:
:         prev, term = term, reducer(term)
:     return term

** TODO Finish lambda calculus reducer with explanation of ~fix~
** TODO Implement lambda calculus parser so we can run examples in code
** TODO Make lambda calculator iterative?
** TODO Implement, explain alpha renamer

* Uses for lambda calculus

Lambda calculus remains a classic way of modeling computation. The
concepts are simple enough to be understood by beginners, yet
introduces enough complexity to model any algorithm. Many issues with
language implementation are worked out with lambda calculus
implementations: for example, alpha renaming is a real compilation
strategy which simplifies (and possibly optimizes) variable
lookup. More broadly, modern languages as diverse as Python and
Haskell are indebted to lambda calculus and the research accomplished
using it.

A lambda calculus reducer is simple enough to implement that it is
often used to prove Turing-completeness. When a language is
Turing-complete, it shares with Lambda calculus the power of being
able to simulate any algorithm. When a language has this power, it is
impossible to prove that a program in that language will halt. That is
to say, there exists no algorithm which accepts every program written
in a Turing-complete language and returns whether or not that program
runs forever. In fact, the notion of Turing-completeness, and lambda
calculus itself, were originally invented as proof of this. Many other
"languages", as diverse as Conway's Game of Life, SQL, a number of
video games such as Minecraft, etc. are Turing-complete. However,
lambda calculus continues to be used, particularly in type theory
where lambda calculi augmented with various type systems are studied.
